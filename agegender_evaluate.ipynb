{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate age & gender classifier with test data\n",
    "\n",
    "### Source\n",
    "* agegender_train.ipynb\n",
    "* agegender_train.py\n",
    "* agegender_predict.py\n",
    "\n",
    "### Setup\n",
    "\n",
    "Remember: \n",
    "\n",
    "* select GPU used for model training and\n",
    "* run jupyter notebook on the port that is not used e.g.\n",
    "\n",
    "$    jupyter notebook --port 5555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select GPU used for model training\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # first gpu\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "# from keras.applications.vgg16 import VGG16\n",
    "# from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATIONS=''\n",
    "DATASET_NAME=''\n",
    "MODELS=\"\"\n",
    "DATASET_ROOT_PATH=\"\"\n",
    "OPTIONAL_MODE=\"\"\n",
    "DATA_AUGUMENTATION=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >> FORMAT: sys_argv = [ANNOTATIONS, MODELS, DATASET_NAME, DATASET_ROOT_PATH, EXTRA_MODE]\n",
    "# \"usage: python agegender_predict.py [gender/age/age101/emotion] [inceptionv3/vgg16/squeezenet/octavio] [adience/imdb/utk/appareal/vggface2/empty] [datasetroot(optional)] [benchmark/caffemodel(optional)]\"\n",
    "from utils import get_local_dataset_root_path\n",
    "# sys_argv = [\"gender\", \"vgg16\", \"imdb\", get_local_dataset_root_path()]\n",
    "# sys_argv = [\"gender\", \"vgg16\", \"utk\", get_local_dataset_root_path()]\n",
    "# sys_argv = [\"gender\", \"inceptionv3\", \"imdb\", get_local_dataset_root_path()]\n",
    "sys_argv = [\"gender\", \"squeezenet\", \"imdb\", get_local_dataset_root_path()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 0\n",
    "if len(sys_argv) >= start_index+3:\n",
    "  ANNOTATIONS = sys_argv[start_index]\n",
    "  MODELS = sys_argv[start_index+1]\n",
    "  DATASET_NAME = sys_argv[start_index+2]\n",
    "  if len(sys_argv) >= start_index+4:\n",
    "    DATASET_ROOT_PATH=sys_argv[start_index+3]\n",
    "  if len(sys_argv) >= start_index+5:\n",
    "    OPTIONAL_MODE=sys_argv[start_index+4]\n",
    "else:\n",
    "  print(\"usage: python agegender_predict.py [gender/age/age101/emotion] [inceptionv3/vgg16/squeezenet/octavio] [adience/imdb/utk/appareal/vggface2/empty] [datasetroot(optional)] [benchmark/caffemodel(optional)]\")\n",
    "  sys.exit(1)\n",
    "\n",
    "if ANNOTATIONS!=\"gender\" and ANNOTATIONS!=\"age\" and ANNOTATIONS!=\"age101\" and ANNOTATIONS!=\"emotion\":\n",
    "  print(\"unknown annotation mode\");\n",
    "  sys.exit(1)\n",
    "\n",
    "if MODELS!=\"inceptionv3\" and MODELS!=\"vgg16\" and MODELS!=\"squeezenet\" and MODELS!=\"mobilenet\" and MODELS!=\"octavio\":\n",
    "  print(\"unknown network mode\");\n",
    "  sys.exit(1)\n",
    "\n",
    "if DATASET_NAME!=\"adience\" and DATASET_NAME!=\"imdb\" and DATASET_NAME!=\"utk\" and DATASET_NAME!=\"appareal\" and DATASET_NAME!=\"vggface2\" and DATASET_NAME!=\"empty\":\n",
    "  print(\"unknown dataset name\");\n",
    "  sys.exit(1)\n",
    "\n",
    "if OPTIONAL_MODE!=\"\" and OPTIONAL_MODE!=\"benchmark\" and OPTIONAL_MODE!=\"caffemodel\":\n",
    "  print(\"unknown optional mode\");\n",
    "  sys.exit(1)\n",
    "\n",
    "if DATASET_NAME==\"empty\":\n",
    "    DATASET_NAME=\"\"\n",
    "else:\n",
    "    DATASET_NAME='_'+DATASET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_HDF5 = ''\n",
    "CUSTOM_MODEL_HDF5 = '/home/krittametht/__backup_YoloKerasFaceDetection_trained/_imdb_cleaned_2_squeeznet_sgd_lr_1e-3/agegender_gender_squeezenet_imdb.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ANNOTATIONS, MODELS, DATASET_NAME, DATASET_ROOT_PATH, OPTIONAL_MODE)\n",
    "if len(CUSTOM_MODEL_HDF5) > 0:\n",
    "    print(CUSTOM_MODEL_HDF5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGUMENT=\"\"\n",
    "if(DATA_AUGUMENTATION):\n",
    "  AUGUMENT=\"augumented\"\n",
    "\n",
    "MODEL_HDF5=DATASET_ROOT_PATH+'pretrain/agegender_'+ANNOTATIONS+'_'+MODELS+DATASET_NAME+AUGUMENT+'.hdf5'\n",
    "ANNOTATION_WORDS='words/agegender_'+ANNOTATIONS+'_words.txt'\n",
    "\n",
    "if(ANNOTATIONS==\"emotion\"):\n",
    "    ANNOTATION_WORDS='words/emotion_words.txt'\n",
    "\n",
    "if(MODELS==\"octavio\"):\n",
    "    if(ANNOTATIONS==\"emotion\"):\n",
    "        MODEL_HDF5=DATASET_ROOT_PATH+'pretrain/fer2013_mini_XCEPTION.102-0.66.hdf5'\n",
    "    if(ANNOTATIONS==\"gender\"):\n",
    "        MODEL_HDF5=DATASET_ROOT_PATH+'pretrain/gender_mini_XCEPTION.21-0.95.hdf5'\n",
    "\n",
    "# --added\n",
    "if len(CUSTOM_MODEL_HDF5) > 0:\n",
    "    MODEL_HDF5 = CUSTOM_MODEL_HDF5\n",
    "        \n",
    "if(MODELS==\"mobilenet\"):\n",
    "    import keras\n",
    "    from keras.utils.generic_utils import CustomObjectScope\n",
    "    with CustomObjectScope({'relu6': keras.applications.mobilenet.relu6,'DepthwiseConv2D': keras.applications.mobilenet.DepthwiseConv2D}):\n",
    "        keras_model = load_model(MODEL_HDF5)\n",
    "else:\n",
    "    keras_model = load_model(MODEL_HDF5)\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to caffe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OPTIONAL_MODE==\"caffemodel\":\n",
    "    os.environ[\"GLOG_minloglevel\"] = \"2\"\n",
    "    import caffe\n",
    "    import keras2caffe\n",
    "    prototxt=DATASET_ROOT_PATH+'pretrain/agegender_'+ANNOTATIONS+'_'+MODELS+DATASET_NAME+'.prototxt'\n",
    "    caffemodel=DATASET_ROOT_PATH+'pretrain/agegender_'+ANNOTATIONS+'_'+MODELS+DATASET_NAME+'.caffemodel'\n",
    "    keras2caffe.convert(keras_model, prototxt, caffemodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OPTIONAL_MODE==\"benchmark\":\n",
    "    BENCHMARK_DATASET_NAME=\"imdb\"\n",
    "    BENCHMARK_DATASET_TARGET=\"validation\"\n",
    "    BATCH_SIZE=64\n",
    "\n",
    "    shape = keras_model.layers[0].get_output_at(0).get_shape().as_list()\n",
    "\n",
    "    disp_generator = ImageDataGenerator(rescale=1.0 / 255).flow_from_directory(\n",
    "       DATASET_ROOT_PATH+'dataset/agegender_'+BENCHMARK_DATASET_NAME+'/annotations/'+ANNOTATIONS+'/'+BENCHMARK_DATASET_TARGET,\n",
    "       target_size=(shape[1], shape[2]),\n",
    "       batch_size=BATCH_SIZE,\n",
    "       class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    DISTRIBUTION_FILE=DATASET_ROOT_PATH+'pretrain/benchmark_'+ANNOTATIONS+\"_\"+MODELS+DATASET_NAME+'.png'\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_axes((0.1, 0.6, 0.8, 0.3))\n",
    "    ax2 = fig.add_axes((0.1, 0.1, 0.8, 0.3))\n",
    "    ax1.tick_params(labelbottom=\"on\")\n",
    "    ax2.tick_params(labelleft=\"on\")\n",
    "\n",
    "    max_cnt=len(disp_generator.filenames)\n",
    "    #max_cnt=10\n",
    "\n",
    "    x=np.zeros((max_cnt))\n",
    "    y=np.zeros((max_cnt))\n",
    "    t=np.zeros((max_cnt))\n",
    "\n",
    "    cnt=0\n",
    "    heatmap=np.zeros((len(disp_generator.class_indices),len(disp_generator.class_indices)))\n",
    "    for x_batch, y_batch in disp_generator:\n",
    "        for i in range(BATCH_SIZE):\n",
    "            x[cnt]=y_batch[i][0]\n",
    "            t[cnt]=y_batch[i].argmax()\n",
    "\n",
    "            data=x_batch[i]\n",
    "            data.shape = (1,) + data.shape\n",
    "            pred = keras_model.predict(data)[0]\n",
    "            cls = pred.argmax()\n",
    "\n",
    "            y[cnt]=cls\n",
    "\n",
    "            heatmap[int(y[cnt]),int(t[cnt])]=heatmap[int(y[cnt]),int(t[cnt])]+1\n",
    "\n",
    "            cnt=cnt+1\n",
    "            print(\"\"+str(cnt)+\"/\"+str(max_cnt)+\" ground truth:\"+str(y_batch[i].argmax())+\" predicted:\"+str(cls))\n",
    "            if cnt>=max_cnt:\n",
    "                break\n",
    "        if cnt>=max_cnt:\n",
    "            break\n",
    "\n",
    "    ax1.pcolor(heatmap, cmap=plt.cm.Blues)\n",
    "    if heatmap.shape[0]<=2:\n",
    "        for y in range(heatmap.shape[0]):\n",
    "            for x in range(heatmap.shape[1]):\n",
    "                ax1.text(x + 0.5, y + 0.5, '%.4f' % heatmap[y, x],\n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center',\n",
    "                )\n",
    "\n",
    "    ax1.set_title('ground truth vs predicted '+ANNOTATIONS)\n",
    "    ax1.set_xlabel(ANNOTATIONS+'(ground truth)')\n",
    "    ax1.set_ylabel(ANNOTATIONS+'(predicted)')\n",
    "    ax1.legend(loc='upper right')\n",
    "\n",
    "    ax2.hist(t, bins=len(disp_generator.class_indices))\n",
    "    ax2.set_title('distribution of ground truth '+ANNOTATIONS)\n",
    "    ax2.set_xlabel(ANNOTATIONS+'(ground truth)')\n",
    "    ax2.set_ylabel('count')\n",
    "    ax2.legend(loc='upper right')\n",
    "\n",
    "    fig.savefig(DISTRIBUTION_FILE)\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "# BATCH_SIZE = 32\n",
    "\n",
    "# BENCHMARK_DATASET_NAME=\"imdb\"\n",
    "BENCHMARK_DATASET_NAME=\"utk\"\n",
    "# BENCHMARK_DATASET_TARGET=\"validation\"\n",
    "BENCHMARK_DATASET_TARGET=\"all\"\n",
    "\n",
    "shape = keras_model.layers[0].get_output_at(0).get_shape().as_list()\n",
    "# print(shape)\n",
    "\n",
    "benchmark_dataset_path = DATASET_ROOT_PATH+'dataset/agegender_'+BENCHMARK_DATASET_NAME+'/annotations/'+ANNOTATIONS+'/'+BENCHMARK_DATASET_TARGET\n",
    "\n",
    "# >> custom path\n",
    "# benchmark_dataset_path = DATASET_ROOT_PATH+'dataset/agegender_'+BENCHMARK_DATASET_NAME+'/annotations/'+'gender_rm_age_001_to_010/all'\n",
    "# benchmark_dataset_path = DATASET_ROOT_PATH+'dataset/agegender_'+BENCHMARK_DATASET_NAME+'/annotations/'+'gender/all'\n",
    "# benchmark_dataset_path = DATASET_ROOT_PATH+'dataset/agegender_'+BENCHMARK_DATASET_NAME+'/annotations/'+'gender/validation'\n",
    "# benchmark_dataset_path = DATASET_ROOT_PATH+'dataset/agegender_'+BENCHMARK_DATASET_NAME+'_crop_m-4'+'/annotations/'+'gender/all'\n",
    "# benchmark_dataset_path = DATASET_ROOT_PATH+'dataset/agegender_'+BENCHMARK_DATASET_NAME+'_crop_m-4'+'/annotations/'+'gender_rm_age_001_to_005/all'\n",
    "# benchmark_dataset_path = DATASET_ROOT_PATH+'dataset/agegender_'+BENCHMARK_DATASET_NAME+'_crop_m-4'+'/annotations/'+'gender_rm_age_001_to_010/all'\n",
    "benchmark_dataset_path = DATASET_ROOT_PATH+'dataset/KBTG_staff_photo_resize/defined_crop_m-4/all'\n",
    "print(benchmark_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255\n",
    "  )\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    benchmark_dataset_path,\n",
    "    target_size=(shape[1], shape[2]),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "# print(test_generator.target_size)\n",
    "\n",
    "test_data_n = len(test_generator.filenames)\n",
    "\n",
    "print(\"Test data count : \"+str(test_data_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = keras_model.evaluate_generator(\n",
    "    generator=test_generator,\n",
    "    verbose=1,\n",
    "    steps=test_data_n//BATCH_SIZE\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_generator.directory)\n",
    "for a,b in zip(keras_model.metrics_names, eval_results):\n",
    "    print(a, \":\\t\", \"%.6f\" % b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

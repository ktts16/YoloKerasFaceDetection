{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train age & gender classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path,sys\n",
    "import numpy as np\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "from keras.layers.convolutional import Convolution2D, Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import InputLayer\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D,AveragePooling2D,Input\n",
    "from keras.layers import SeparableConv2D\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import layers\n",
    "\n",
    "import keras.callbacks\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATIONS=''\n",
    "MODELS=''\n",
    "DATASET_NAME=''\n",
    "DATASET_ROOT_PATH='./'  #/Volumes/ST5/keras/\n",
    "EXTRA_MODE=''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >> FORMAT: sys_argv = [ANNOTATIONS, MODELS, DATASET_NAME, DATASET_ROOT_PATH, EXTRA_MODE]\n",
    "# \"usage: python agegender_train.py [gender/age/age101] [inceptionv3/vgg16/squeezenet/squeezenet2/mobilenet] [adience/imdb/utk/appareal/vggface2/merged] [datasetroot(optional)] [augumented/hdf5(optional)]\")\n",
    "from utils import get_local_dataset_root_path\n",
    "# sys_argv = [\"gender\", \"vgg16\", \"imdb\", get_local_dataset_root_path()]\n",
    "sys_argv = [\"gender\", \"vgg16\", \"utk\", get_local_dataset_root_path()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 0\n",
    "if len(sys_argv) >= start_index+3:\n",
    "  ANNOTATIONS = sys_argv[start_index]\n",
    "  MODELS = sys_argv[start_index+1]\n",
    "  DATASET_NAME = sys_argv[start_index+2]\n",
    "  if len(sys_argv) >= start_index+4:\n",
    "    DATASET_ROOT_PATH=sys_argv[start_index+3]\n",
    "  if len(sys_argv) >= start_index+5:\n",
    "    EXTRA_MODE=sys_argv[start_index+4]\n",
    "else:\n",
    "  print(\"usage: python agegender_train.py [gender/age/age101] [inceptionv3/vgg16/squeezenet/squeezenet2/mobilenet] [adience/imdb/utk/appareal/vggface2/merged] [datasetroot(optional)] [augumented/hdf5(optional)]\")\n",
    "  sys.exit(1)\n",
    "\n",
    "if ANNOTATIONS!=\"gender\" and ANNOTATIONS!=\"age\" and ANNOTATIONS!=\"age101\":\n",
    "  print(\"unknown annotation mode\");\n",
    "  sys.exit(1)\n",
    "\n",
    "if MODELS!=\"inceptionv3\" and MODELS!=\"vgg16\" and MODELS!=\"squeezenet\" and MODELS!=\"squeezenet2\" and MODELS!=\"mobilenet\":\n",
    "  print(\"unknown network mode\");\n",
    "  sys.exit(1)\n",
    "\n",
    "if DATASET_NAME!=\"adience\" and DATASET_NAME!=\"imdb\" and DATASET_NAME!=\"utk\" and DATASET_NAME!=\"appareal\" and DATASET_NAME!=\"vggface2\" and DATASET_NAME!=\"merged\":\n",
    "  print(\"unknown dataset name\");\n",
    "  sys.exit(1)\n",
    "\n",
    "if EXTRA_MODE!=\"\" and EXTRA_MODE!=\"augumented\" and EXTRA_MODE!=\"hdf5\":\n",
    "  print(\"unknown extra mode\");\n",
    "  sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ANNOTATIONS, MODELS, DATASET_NAME, DATASET_ROOT_PATH, EXTRA_MODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRA_MODE!=\"augumented\":\n",
    "  DATA_AUGUMENTATION=False\n",
    "else:\n",
    "  DATA_AUGUMENTATION=True\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "if ANNOTATIONS=='age101':\n",
    "  EPOCS = 100\n",
    "else:\n",
    "  EPOCS = 25\n",
    "\n",
    "EXTRA_PREFIX=\"\"\n",
    "if EXTRA_MODE!=\"\":\n",
    "  EXTRA_PREFIX=\"_\"+EXTRA_MODE\n",
    "\n",
    "if ANNOTATIONS=='age':\n",
    "  N_CATEGORIES=8\n",
    "if ANNOTATIONS=='gender':\n",
    "  N_CATEGORIES=2\n",
    "if ANNOTATIONS=='age101':\n",
    "  N_CATEGORIES=101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "OUTPUT_ROOT_PATH = os.path.join(str(Path.home()),'github','YoloKerasFaceDetection')\n",
    "\n",
    "PLOT_FILE=os.path.join(OUTPUT_ROOT_PATH,'pretrain/agegender_'+ANNOTATIONS+'_'+MODELS+'_'+DATASET_NAME+EXTRA_PREFIX+'.png')\n",
    "MODEL_HDF5=os.path.join(OUTPUT_ROOT_PATH,'pretrain/agegender_'+ANNOTATIONS+'_'+MODELS+'_'+DATASET_NAME+EXTRA_PREFIX+'.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limit GPU memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as backend\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(MODELS=='inceptionv3'):\n",
    "   IMAGE_SIZE = 299\n",
    "   input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "   base_model = InceptionV3(weights='imagenet', include_top=False,input_tensor=input_tensor)\n",
    "\n",
    "   x = base_model.output\n",
    "   x = GlobalAveragePooling2D()(x)\n",
    "   x = Dense(512, activation='relu')(x)\n",
    "   predictions = Dense(N_CATEGORIES, activation='softmax')(x)\n",
    "\n",
    "   model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "   layer_num = len(model.layers)\n",
    "   for layer in model.layers[:279]:\n",
    "      layer.trainable = False\n",
    "   for layer in model.layers[279:]:\n",
    "      layer.trainable = True\n",
    "elif(MODELS=='vgg16'):\n",
    "   IMAGE_SIZE = 224\n",
    "   input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "   base_model = VGG16(weights='imagenet', include_top=False,input_tensor=input_tensor)\n",
    "   x = base_model.output\n",
    "   x = GlobalAveragePooling2D()(x)\n",
    "   x = Dense(1024, activation='relu')(x)\n",
    "   predictions = Dense(N_CATEGORIES, activation='softmax')(x)\n",
    "   model = Model(inputs=base_model.input, outputs=predictions)\n",
    "   for layer in base_model.layers[:15]:\n",
    "      layer.trainable = False\n",
    "elif(MODELS=='squeezenet'):\n",
    "  IMAGE_SIZE=227\n",
    "  import sys\n",
    "  sys.path.append('../keras-squeezenet-master')\n",
    "  from keras_squeezenet import SqueezeNet\n",
    "  input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "  base_model = SqueezeNet(weights=\"imagenet\", include_top=False, input_tensor=input_tensor)\n",
    "  x = base_model.output\n",
    "  x = GlobalAveragePooling2D()(x)\n",
    "  x = Dense(1024, activation='relu')(x)\n",
    "  predictions = Dense(N_CATEGORIES, activation='softmax')(x)\n",
    "  model = Model(inputs=base_model.input, outputs=predictions)\n",
    "elif(MODELS=='squeezenet2'):\n",
    "  IMAGE_SIZE=64\n",
    "  import sys\n",
    "  sys.path.append('../keras-squeezenet-master')\n",
    "  from keras_squeezenet import SqueezeNet\n",
    "  input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "  base_model = SqueezeNet(include_top=False, input_tensor=input_tensor)\n",
    "  x = base_model.output\n",
    "  x = Dropout(0.5, name='drop9')(x)\n",
    "  x = Convolution2D(N_CATEGORIES, (1, 1), padding='valid', name='conv10')(x)\n",
    "  x = Activation('relu', name='relu_conv10')(x)\n",
    "  x = GlobalAveragePooling2D()(x)\n",
    "  predictions = Activation('softmax', name='loss')(x)\n",
    "  model = Model(inputs=base_model.input, outputs=predictions)\n",
    "elif(MODELS=='mobilenet'):\n",
    "  IMAGE_SIZE=128\n",
    "  input_shape = (IMAGE_SIZE,IMAGE_SIZE,3)\n",
    "  base_model = MobileNet(weights='imagenet', include_top=False,input_shape=input_shape)\n",
    "  x = base_model.output\n",
    "  x = GlobalAveragePooling2D()(x)\n",
    "  x = Dense(1024, activation='relu')(x)\n",
    "  predictions = Dense(N_CATEGORIES, activation='softmax')(x)\n",
    "  model = Model(inputs=base_model.input, outputs=predictions)\n",
    "else:\n",
    "   raise Exception('invalid model name')\n",
    "\n",
    "if(MODELS=='inceptionv3' or MODELS=='vgg16' or MODELS=='squeezenet' or MODELS=='squeezenet2' or MODELS=='mobilenet'):\n",
    "  #for fine tuning\n",
    "  from keras.optimizers import SGD\n",
    "  model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "else:\n",
    "  #for full training\n",
    "  from keras.optimizers import Adagrad\n",
    "  model.compile(optimizer=Adagrad(lr=0.01, epsilon=1e-08, decay=0.0), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference from https://github.com/yu4u/age-gender-estimation/blob/master/random_eraser.py\n",
    "# https://github.com/yu4u/age-gender-estimation/blob/master/LICENSE\n",
    "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255):\n",
    "    def eraser(input_img):\n",
    "        img_h, img_w, _ = input_img.shape\n",
    "        p_1 = np.random.rand()\n",
    "\n",
    "        if p_1 > p:\n",
    "            return input_img\n",
    "\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = int(np.sqrt(s / r))\n",
    "            h = int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, img_w)\n",
    "            top = np.random.randint(0, img_h)\n",
    "\n",
    "            if left + w <= img_w and top + h <= img_h:\n",
    "                break\n",
    "\n",
    "        c = np.random.uniform(v_l, v_h)\n",
    "        input_img[top:top + h, left:left + w, :] = c\n",
    "\n",
    "        return input_img\n",
    "    return eraser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For machine with CPU: preparation for testing this notebook\n",
    "*** WARNING: run this section only once for each input pair ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_dir_subdir_and_subset_of_files(SRCDIR, DESTDIR, N_FILES_TO_COPY):\n",
    "    # if DESTDIR does not exist, create it.\n",
    "    if not os.path.exists(DESTDIR):\n",
    "        os.mkdir(DESTDIR)\n",
    "\n",
    "    # create subfolders of SRCDIR in DESTDIR\n",
    "    for subfolder in os.listdir(SRCDIR):\n",
    "        subdir = os.path.join(DESTDIR,subfolder)\n",
    "        if not os.path.exists(subdir):\n",
    "            os.mkdir(subdir)\n",
    "        total_num_files = ! ls -1 \"$SRCDIR/$subfolder\" | wc -l\n",
    "        total_num_files = int(total_num_files[0])\n",
    "        if N_FILES_TO_COPY < total_num_files:\n",
    "            # copy the first N_FILES_TO_COPY files to the subfolder of DESTDIR\n",
    "            ! find \"$SRCDIR/$subfolder\" -maxdepth 1 -type f | head -$N_FILES_TO_COPY | xargs cp -t \"$DESTDIR/$subfolder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input pairs\n",
    "data_subset, N_FILES_TO_COPY = \"train\", 90\n",
    "# data_subset, N_FILES_TO_COPY  = \"validation\", 30\n",
    "\n",
    "if N_FILES_TO_COPY < BATCH_SIZE:\n",
    "    print('Error: N_FILES_TO_COPY (total number of files) is less than BATCH_SIZE.')\n",
    "else:\n",
    "    path_annotation = DATASET_ROOT_PATH+'dataset/agegender_'+DATASET_NAME+'/annotations/'+ANNOTATIONS\n",
    "    SRCDIR = os.path.join(path_annotation,data_subset)\n",
    "    DESTDIR = os.path.join(path_annotation,data_subset+'_small')\n",
    "    copy_dir_subdir_and_subset_of_files(SRCDIR, DESTDIR, N_FILES_TO_COPY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cpu_only = False # FOR MACHINE WITH GPU\n",
    "# is_cpu_only = True # FOR MACHINE WITHOUT GPU\n",
    "\n",
    "if is_cpu_only: # for testing code in this notebook only\n",
    "    folder_train, folder_validation = 'train_small', 'validation_small'\n",
    "    BATCH_SIZE = 2\n",
    "    EPOCS = 10\n",
    "else:\n",
    "    folder_train, folder_validation = 'train', 'validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRA_MODE!=\"hdf5\":\n",
    "  preprocessing_function=None\n",
    "  if DATA_AUGUMENTATION:\n",
    "    preprocessing_function=get_random_eraser(v_l=0, v_h=255)\n",
    "\n",
    "  train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=10,\n",
    "    preprocessing_function=preprocessing_function\n",
    "  )\n",
    "\n",
    "  test_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255\n",
    "  )\n",
    "\n",
    "  train_generator = train_datagen.flow_from_directory(\n",
    "    DATASET_ROOT_PATH+'dataset/agegender_'+DATASET_NAME+'/annotations/'+ANNOTATIONS+'/'+folder_train,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    "  )\n",
    "\n",
    "  validation_generator = test_datagen.flow_from_directory(\n",
    "    DATASET_ROOT_PATH+'dataset/agegender_'+DATASET_NAME+'/annotations/'+ANNOTATIONS+'/'+folder_validation,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    "  )\n",
    "\n",
    "  training_data_n = len(train_generator.filenames)\n",
    "  validation_data_n = len(validation_generator.filenames)\n",
    "\n",
    "  print(\"Training data count : \"+str(training_data_n))\n",
    "  print(\"Validation data count : \"+str(validation_data_n))\n",
    "\n",
    "  if DATASET_NAME!=\"imdb\" and DATASET_NAME!=\"merged\":\n",
    "    training_data_n=training_data_n*4  # Data augumentation\n",
    "    print(\"Training data augumented count : \"+str(training_data_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('BATCH_SIZE:', BATCH_SIZE)\n",
    "print('EPOCS:', EPOCS)\n",
    "print('training_data_n:', training_data_n)\n",
    "print('validation_data_n:', validation_data_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRA_MODE==\"hdf5\":\n",
    "  from keras.utils.io_utils import HDF5Matrix\n",
    "  HDF5_PATH=DATASET_ROOT_PATH+\"dataset/\"+DATASET_NAME+\"_\"+ANNOTATIONS+\".h5\"\n",
    "  x_train = HDF5Matrix(HDF5_PATH, 'training_x')\n",
    "  y_train = HDF5Matrix(HDF5_PATH, 'training_y')\n",
    "  x_validation = HDF5Matrix(HDF5_PATH, 'validation_x')\n",
    "  y_validation = HDF5Matrix(HDF5_PATH, 'validation_y')\n",
    "  fit = model.fit(\n",
    "    epochs=EPOCS,\n",
    "    x=x_train, \n",
    "    y=y_train,\n",
    "    validation_data=(x_validation,y_validation),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle='batch'\n",
    "  )\n",
    "else:\n",
    "  fit = model.fit_generator(train_generator,\n",
    "    epochs=EPOCS,\n",
    "    verbose=1,\n",
    "    validation_data=validation_generator,\n",
    "    steps_per_epoch=training_data_n//BATCH_SIZE,\n",
    "    validation_steps=validation_data_n//BATCH_SIZE\n",
    "  )\n",
    "\n",
    "model.save(MODEL_HDF5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (axL, axR) = plt.subplots(ncols=2, figsize=(10,4))\n",
    "\n",
    "# loss\n",
    "def plot_history_loss(fit):\n",
    "    # Plot the loss in the history\n",
    "    axL.plot(fit.history['loss'],label=\"loss for training\")\n",
    "    axL.plot(fit.history['val_loss'],label=\"loss for validation\")\n",
    "    axL.set_title('model loss')\n",
    "    axL.set_xlabel('epoch')\n",
    "    axL.set_ylabel('loss')\n",
    "    axL.legend(loc='upper right')\n",
    "\n",
    "# acc\n",
    "def plot_history_acc(fit):\n",
    "    # Plot the loss in the history\n",
    "    axR.plot(fit.history['acc'],label=\"accuracy for training\")\n",
    "    axR.plot(fit.history['val_acc'],label=\"accuracy for validation\")\n",
    "    axR.set_title('model accuracy')\n",
    "    axR.set_xlabel('epoch')\n",
    "    axR.set_ylabel('accuracy')\n",
    "    axR.legend(loc='upper right')\n",
    "\n",
    "plot_history_loss(fit)\n",
    "plot_history_acc(fit)\n",
    "fig.savefig(PLOT_FILE)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

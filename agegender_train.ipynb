{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train age & gender classifier\n",
    "\n",
    "### Setup\n",
    "\n",
    "Remember: \n",
    "\n",
    "* select GPU used for model training and\n",
    "* run jupyter notebook on the port that is not used e.g.\n",
    "\n",
    "$    jupyter notebook --port 5555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select GPU used for model training\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # first gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path,sys\n",
    "import numpy as np\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "from keras.layers.convolutional import Convolution2D, Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import InputLayer\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D,AveragePooling2D,Input\n",
    "from keras.layers import SeparableConv2D\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import layers\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATIONS=''\n",
    "MODELS=''\n",
    "DATASET_NAME=''\n",
    "DATASET_ROOT_PATH='./'  #/Volumes/ST5/keras/\n",
    "EXTRA_MODE=''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >> FORMAT: sys_argv = [ANNOTATIONS, MODELS, DATASET_NAME, DATASET_ROOT_PATH, EXTRA_MODE]\n",
    "# \"usage: python agegender_train.py [gender/age/age101] [inceptionv3/vgg16/squeezenet/squeezenet2/mobilenet] [adience/imdb/utk/appareal/vggface2/merged] [datasetroot(optional)] [augumented/hdf5(optional)]\")\n",
    "from utils import get_local_dataset_root_path\n",
    "# sys_argv = [\"gender\", \"vgg16\", \"imdb\", get_local_dataset_root_path()]\n",
    "# sys_argv = [\"gender\", \"vgg16\", \"utk\", get_local_dataset_root_path()]\n",
    "sys_argv = [\"gender\", \"squeezenet\", \"imdb\", get_local_dataset_root_path()]\n",
    "\n",
    "custom_model = False\n",
    "custom_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 0\n",
    "if len(sys_argv) >= start_index+3:\n",
    "  ANNOTATIONS = sys_argv[start_index]\n",
    "  MODELS = sys_argv[start_index+1]\n",
    "  DATASET_NAME = sys_argv[start_index+2]\n",
    "  if len(sys_argv) >= start_index+4:\n",
    "    DATASET_ROOT_PATH=sys_argv[start_index+3]\n",
    "  if len(sys_argv) >= start_index+5:\n",
    "    EXTRA_MODE=sys_argv[start_index+4]\n",
    "else:\n",
    "  print(\"usage: python agegender_train.py [gender/age/age101] [inceptionv3/vgg16/squeezenet/squeezenet2/mobilenet] [adience/imdb/utk/appareal/vggface2/merged] [datasetroot(optional)] [augumented/hdf5(optional)]\")\n",
    "  sys.exit(1)\n",
    "\n",
    "if ANNOTATIONS!=\"gender\" and ANNOTATIONS!=\"age\" and ANNOTATIONS!=\"age101\":\n",
    "  print(\"unknown annotation mode\");\n",
    "  sys.exit(1)\n",
    "\n",
    "if MODELS!=\"inceptionv3\" and MODELS!=\"vgg16\" and MODELS!=\"squeezenet\" and MODELS!=\"squeezenet2\" and MODELS!=\"mobilenet\":\n",
    "  print(\"unknown network mode\");\n",
    "  sys.exit(1)\n",
    "\n",
    "if DATASET_NAME!=\"adience\" and DATASET_NAME!=\"imdb\" and DATASET_NAME!=\"utk\" and DATASET_NAME!=\"appareal\" and DATASET_NAME!=\"vggface2\" and DATASET_NAME!=\"merged\":\n",
    "  print(\"unknown dataset name\");\n",
    "  sys.exit(1)\n",
    "\n",
    "if EXTRA_MODE!=\"\" and EXTRA_MODE!=\"augumented\" and EXTRA_MODE!=\"hdf5\":\n",
    "  print(\"unknown extra mode\");\n",
    "  sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ANNOTATIONS, MODELS, DATASET_NAME, DATASET_ROOT_PATH, EXTRA_MODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRA_MODE!=\"augumented\":\n",
    "  DATA_AUGUMENTATION=False\n",
    "else:\n",
    "  DATA_AUGUMENTATION=True\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "if ANNOTATIONS=='age101':\n",
    "  EPOCS = 100\n",
    "else:\n",
    "  EPOCS = 25\n",
    "\n",
    "EXTRA_PREFIX=\"\"\n",
    "if EXTRA_MODE!=\"\":\n",
    "  EXTRA_PREFIX=\"_\"+EXTRA_MODE\n",
    "\n",
    "if ANNOTATIONS=='age':\n",
    "  N_CATEGORIES=8\n",
    "if ANNOTATIONS=='gender':\n",
    "  N_CATEGORIES=2\n",
    "if ANNOTATIONS=='age101':\n",
    "  N_CATEGORIES=101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "OUTPUT_ROOT_PATH = os.path.join(os.path.dirname(os.path.abspath('')),'YoloKerasFaceDetection')\n",
    "\n",
    "PLOT_FILE=os.path.join(OUTPUT_ROOT_PATH,'pretrain/agegender_'+ANNOTATIONS+'_'+MODELS+'_'+DATASET_NAME+EXTRA_PREFIX+'.png')\n",
    "MODEL_HDF5=os.path.join(OUTPUT_ROOT_PATH,'pretrain/agegender_'+ANNOTATIONS+'_'+MODELS+'_'+DATASET_NAME+EXTRA_PREFIX+'.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limit GPU memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as backend\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(MODELS=='inceptionv3'):\n",
    "   IMAGE_SIZE = 299\n",
    "   input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "   base_model = InceptionV3(weights='imagenet', include_top=False,input_tensor=input_tensor)\n",
    "\n",
    "   x = base_model.output\n",
    "   x = GlobalAveragePooling2D()(x)\n",
    "   x = Dense(512, activation='relu')(x)\n",
    "   predictions = Dense(N_CATEGORIES, activation='softmax')(x)\n",
    "\n",
    "   model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "   layer_num = len(model.layers)\n",
    "   for layer in model.layers[:279]:\n",
    "      layer.trainable = False\n",
    "   for layer in model.layers[279:]:\n",
    "      layer.trainable = True\n",
    "elif(MODELS=='vgg16'):\n",
    "   IMAGE_SIZE = 224\n",
    "   input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "   base_model = VGG16(weights='imagenet', include_top=False,input_tensor=input_tensor)\n",
    "   x = base_model.output\n",
    "   x = GlobalAveragePooling2D()(x)\n",
    "   x = Dense(1024, activation='relu')(x)\n",
    "   predictions = Dense(N_CATEGORIES, activation='softmax')(x)\n",
    "   model = Model(inputs=base_model.input, outputs=predictions)\n",
    "   for layer in base_model.layers[:15]:\n",
    "      layer.trainable = False\n",
    "elif(MODELS=='squeezenet'):\n",
    "  IMAGE_SIZE=227\n",
    "  import sys\n",
    "  sys.path.append('../keras-squeezenet-master')\n",
    "  from keras_squeezenet import SqueezeNet\n",
    "  input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "  base_model = SqueezeNet(weights=\"imagenet\", include_top=False, input_tensor=input_tensor)\n",
    "  x = base_model.output\n",
    "  x = GlobalAveragePooling2D()(x)\n",
    "  if custom_model:\n",
    "    # rationale: generally, input size of Dense layer following pooling layer should be smaller that of pooling layer.\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "  else:\n",
    "    x = Dense(1024, activation='relu')(x) # original model from github\n",
    "  predictions = Dense(N_CATEGORIES, activation='softmax')(x)\n",
    "  model = Model(inputs=base_model.input, outputs=predictions)\n",
    "elif(MODELS=='squeezenet2'):\n",
    "  IMAGE_SIZE=64\n",
    "  import sys\n",
    "  sys.path.append('../keras-squeezenet-master')\n",
    "  from keras_squeezenet import SqueezeNet\n",
    "  input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "  base_model = SqueezeNet(include_top=False, input_tensor=input_tensor)\n",
    "  x = base_model.output\n",
    "  x = Dropout(0.5, name='drop9')(x)\n",
    "  x = Convolution2D(N_CATEGORIES, (1, 1), padding='valid', name='conv10')(x)\n",
    "  x = Activation('relu', name='relu_conv10')(x)\n",
    "  x = GlobalAveragePooling2D()(x)\n",
    "  predictions = Activation('softmax', name='loss')(x)\n",
    "  model = Model(inputs=base_model.input, outputs=predictions)\n",
    "elif(MODELS=='mobilenet'):\n",
    "  IMAGE_SIZE=128\n",
    "  input_shape = (IMAGE_SIZE,IMAGE_SIZE,3)\n",
    "  base_model = MobileNet(weights='imagenet', include_top=False,input_shape=input_shape)\n",
    "  x = base_model.output\n",
    "  x = GlobalAveragePooling2D()(x)\n",
    "  x = Dense(1024, activation='relu')(x)\n",
    "  predictions = Dense(N_CATEGORIES, activation='softmax')(x)\n",
    "  model = Model(inputs=base_model.input, outputs=predictions)\n",
    "else:\n",
    "   raise Exception('invalid model name')\n",
    "\n",
    "if(MODELS=='inceptionv3' or MODELS=='vgg16' or MODELS=='squeezenet' or MODELS=='squeezenet2' or MODELS=='mobilenet'):\n",
    "  #for fine tuning\n",
    "  from keras.optimizers import SGD\n",
    "#   model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "  model.compile(optimizer=SGD(lr=0.001, momentum=0.9), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "else:\n",
    "  #for full training\n",
    "  from keras.optimizers import Adagrad\n",
    "  model.compile(optimizer=Adagrad(lr=0.01, epsilon=1e-08, decay=0.0), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "LR = model.optimizer.lr.numpy()\n",
    "OPT = model.optimizer.__class__.__name__ #optimizer\n",
    "log_folder_name = '_'.join([ANNOTATIONS, MODELS, DATASET_NAME, OPT, 'lr_%.3e' % LR])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference from https://github.com/yu4u/age-gender-estimation/blob/master/random_eraser.py\n",
    "# https://github.com/yu4u/age-gender-estimation/blob/master/LICENSE\n",
    "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255):\n",
    "    def eraser(input_img):\n",
    "        img_h, img_w, _ = input_img.shape\n",
    "        p_1 = np.random.rand()\n",
    "\n",
    "        if p_1 > p:\n",
    "            return input_img\n",
    "\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = int(np.sqrt(s / r))\n",
    "            h = int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, img_w)\n",
    "            top = np.random.randint(0, img_h)\n",
    "\n",
    "            if left + w <= img_w and top + h <= img_h:\n",
    "                break\n",
    "\n",
    "        c = np.random.uniform(v_l, v_h)\n",
    "        input_img[top:top + h, left:left + w, :] = c\n",
    "\n",
    "        return input_img\n",
    "    return eraser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For machine with CPU: preparation for testing this notebook\n",
    "*** WARNING: run this section only once for each input pair ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_dir_subdir_and_subset_of_files(SRCDIR, DESTDIR, N_FILES_TO_COPY):\n",
    "    # if DESTDIR does not exist, create it.\n",
    "    if not os.path.exists(DESTDIR):\n",
    "        os.mkdir(DESTDIR)\n",
    "\n",
    "    # create subfolders of SRCDIR in DESTDIR\n",
    "    for subfolder in os.listdir(SRCDIR):\n",
    "        subdir = os.path.join(DESTDIR,subfolder)\n",
    "        if not os.path.exists(subdir):\n",
    "            os.mkdir(subdir)\n",
    "        total_num_files = ! ls -1 \"$SRCDIR/$subfolder\" | wc -l\n",
    "        total_num_files = int(total_num_files[0])\n",
    "        if N_FILES_TO_COPY < total_num_files:\n",
    "            # copy the first N_FILES_TO_COPY files to the subfolder of DESTDIR\n",
    "            ! find \"$SRCDIR/$subfolder\" -maxdepth 1 -type f | head -$N_FILES_TO_COPY | xargs cp -t \"$DESTDIR/$subfolder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input pairs\n",
    "data_subset, N_FILES_TO_COPY = \"train\", 90\n",
    "# data_subset, N_FILES_TO_COPY  = \"validation\", 30\n",
    "\n",
    "if N_FILES_TO_COPY < BATCH_SIZE:\n",
    "    print('Error: N_FILES_TO_COPY (total number of files) is less than BATCH_SIZE.')\n",
    "else:\n",
    "    path_annotation = DATASET_ROOT_PATH+'dataset/agegender_'+DATASET_NAME+'/annotations/'+ANNOTATIONS\n",
    "    SRCDIR = os.path.join(path_annotation,data_subset)\n",
    "    DESTDIR = os.path.join(path_annotation,data_subset+'_small')\n",
    "    copy_dir_subdir_and_subset_of_files(SRCDIR, DESTDIR, N_FILES_TO_COPY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cpu_only = False # FOR MACHINE WITH GPU\n",
    "# is_cpu_only = True # FOR MACHINE WITHOUT GPU\n",
    "\n",
    "if is_cpu_only: # for testing code in this notebook only\n",
    "    folder_train, folder_validation = 'train_small', 'validation_small'\n",
    "    BATCH_SIZE = 2\n",
    "    EPOCS = 10\n",
    "else:\n",
    "    folder_train, folder_validation = 'train', 'validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRA_MODE!=\"hdf5\":\n",
    "  preprocessing_function=None\n",
    "  if DATA_AUGUMENTATION:\n",
    "    preprocessing_function=get_random_eraser(v_l=0, v_h=255)\n",
    "\n",
    "  train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=10,\n",
    "    preprocessing_function=preprocessing_function\n",
    "  )\n",
    "\n",
    "  test_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255\n",
    "  )\n",
    "\n",
    "  train_generator = train_datagen.flow_from_directory(\n",
    "    DATASET_ROOT_PATH+'dataset/agegender_'+DATASET_NAME+'/annotations/'+ANNOTATIONS+'/'+folder_train,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    "  )\n",
    "\n",
    "  validation_generator = test_datagen.flow_from_directory(\n",
    "    DATASET_ROOT_PATH+'dataset/agegender_'+DATASET_NAME+'/annotations/'+ANNOTATIONS+'/'+folder_validation,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    "  )\n",
    "\n",
    "  training_data_n = len(train_generator.filenames)\n",
    "  validation_data_n = len(validation_generator.filenames)\n",
    "\n",
    "  print(\"Training data count : \"+str(training_data_n))\n",
    "  print(\"Validation data count : \"+str(validation_data_n))\n",
    "\n",
    "  if DATASET_NAME!=\"imdb\" and DATASET_NAME!=\"merged\":\n",
    "    training_data_n=training_data_n*4  # Data augumentation\n",
    "    print(\"Training data augumented count : \"+str(training_data_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('BATCH_SIZE:', BATCH_SIZE)\n",
    "print('EPOCS:', EPOCS)\n",
    "print('training_data_n:', training_data_n)\n",
    "print('validation_data_n:', validation_data_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_dir = 'logs/000/'\n",
    "log_folder_suffix = '000'\n",
    "log_dir = '/'.join(['logs', log_folder_name + '_' + log_folder_suffix])\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging = TensorBoard(log_dir=log_dir)\n",
    "checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
    "    monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRA_MODE==\"hdf5\":\n",
    "  from keras.utils.io_utils import HDF5Matrix\n",
    "  HDF5_PATH=DATASET_ROOT_PATH+\"dataset/\"+DATASET_NAME+\"_\"+ANNOTATIONS+\".h5\"\n",
    "  x_train = HDF5Matrix(HDF5_PATH, 'training_x')\n",
    "  y_train = HDF5Matrix(HDF5_PATH, 'training_y')\n",
    "  x_validation = HDF5Matrix(HDF5_PATH, 'validation_x')\n",
    "  y_validation = HDF5Matrix(HDF5_PATH, 'validation_y')\n",
    "  fit = model.fit(\n",
    "    epochs=EPOCS,\n",
    "    x=x_train, \n",
    "    y=y_train,\n",
    "    validation_data=(x_validation,y_validation),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle='batch'\n",
    "  )\n",
    "else:\n",
    "  fit = model.fit_generator(train_generator,\n",
    "    epochs=EPOCS,\n",
    "    verbose=1,\n",
    "    validation_data=validation_generator,\n",
    "    steps_per_epoch=training_data_n//BATCH_SIZE,\n",
    "    validation_steps=validation_data_n//BATCH_SIZE,\n",
    "    callbacks=[logging, checkpoint, reduce_lr, early_stopping]\n",
    "  )\n",
    "\n",
    "model.save(MODEL_HDF5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_training extracted from /home/krittametht/__backup_YoloKerasFaceDetection_trained/2/agegender_train.ipynb\n",
    "f = open(\"/home/krittametht/__backup_YoloKerasFaceDetection_trained/2/log_training__2__agegender_gender_inceptionv3_imdb__epochs50_cb.txt\", \"r\")\n",
    "log_training = f.read()\n",
    "f.close()\n",
    "# print(log_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_element(ls, idx):\n",
    "    if idx < len(ls):\n",
    "        return ls[idx]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def convert_log_string_to_history_dict(lines):\n",
    "    # convert Keras' model training log [string] into list of dictionaries\n",
    "    '''\n",
    "    structure: epoch dict \n",
    "    - key : data type\n",
    "    - epoch_number : int\n",
    "    - early_stopping : boolean (False)\n",
    "    - lr : float (0)\n",
    "    - loss : float\n",
    "    - accuracy : float\n",
    "    - val_loss : float\n",
    "    - val_accuracy : float\n",
    "    '''\n",
    "    history = []\n",
    "    for li,string in enumerate(lines):\n",
    "        if string.count(\"Epoch \") == 1 and string.count(\"/\") == 1:\n",
    "            epoch_number, nepochs = string[5:].split(\"/\")\n",
    "            epoch_number = int(epoch_number)\n",
    "            #print(current_epoch, nepochs)\n",
    "            epoch_dict = {\"epoch_number\": epoch_number, \"early_stopping\": False, \"lr\": 0.0}\n",
    "            history.append(epoch_dict)\n",
    "            \n",
    "            if epoch_number == 1:\n",
    "                total_nepochs = int(nepochs)\n",
    "\n",
    "            next_string_1 = get_list_element(lines, li+1)\n",
    "            if next_string_1 != None and next_string_1.count(\" - \") == 5:\n",
    "                parts_2 = next_string_1.split(\" - \")\n",
    "                for i in range(2, len(parts_2)):\n",
    "                    key, val = parts_2[i].split(\": \")\n",
    "                    epoch_dict[key] = float(val)\n",
    "                #print(epoch_dict)\n",
    "\n",
    "            next_string_2 = get_list_element(lines, li+2)\n",
    "            if next_string_2 != None and next_string_2.count(\"Epoch \") == 1 and next_string_2.count(\"early stopping\") == 1:\n",
    "                try:\n",
    "                    current_epoch = int(next_string_2[6:6+5])\n",
    "                    if current_epoch == epoch_dict[\"epoch_number\"]:\n",
    "                        epoch_dict[\"early_stopping\"] = True\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            next_string_3 = get_list_element(lines, li+3)\n",
    "            if next_string_3 != None and next_string_3.count(\"Epoch \") == 1 and next_string_3.count(\"ReduceLROnPlateau reducing learning rate to \") == 1:\n",
    "                try:\n",
    "                    current_epoch = int(next_string_3[6:6+5])\n",
    "                    if current_epoch == epoch_dict[\"epoch_number\"]:\n",
    "                        lr = float(next_string_3.split(\"ReduceLROnPlateau reducing learning rate to \")[1][:-1])\n",
    "                        epoch_dict[\"lr\"] = lr\n",
    "                        #print(current_epoch, lr, type(lr))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    return history, total_nepochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [s.strip() for s in log_training.splitlines()]\n",
    "history, total_nepochs = convert_log_string_to_history_dict(lines)\n",
    "# for epoch in history:\n",
    "#     for key, val in epoch.items():\n",
    "#         print(key, val, end=\"\\t\")\n",
    "#     print(\"\")\n",
    "# print(total_nepochs)\n",
    "\n",
    "import pandas as pd\n",
    "history_df = pd.DataFrame.from_dict(history)\n",
    "print(history_df)\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     print(history_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (axL, axR) = plt.subplots(ncols=2, figsize=(10,4))\n",
    "\n",
    "# loss\n",
    "def plot_history_loss_from_df(history_df):\n",
    "    # Plot the loss in the history\n",
    "    axL.plot(history_df['loss'],label=\"loss for training\")\n",
    "    axL.plot(history_df['val_loss'],label=\"loss for validation\")\n",
    "    axL.set_title('model loss')\n",
    "    axL.set_xlabel('epoch')\n",
    "    axL.set_ylabel('loss')\n",
    "    axL.legend(loc='upper right')\n",
    "\n",
    "# acc\n",
    "def plot_history_acc_from_df(history_df):\n",
    "    # Plot the loss in the history\n",
    "    axR.plot(history_df['accuracy'],label=\"accuracy for training\")\n",
    "    axR.plot(history_df['val_accuracy'],label=\"accuracy for validation\")\n",
    "    axR.set_title('model accuracy')\n",
    "    axR.set_xlabel('epoch')\n",
    "    axR.set_ylabel('accuracy')\n",
    "    axR.legend(loc='upper right')\n",
    "\n",
    "plot_history_loss_from_df(history_df)\n",
    "plot_history_acc_from_df(history_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (axL, axR) = plt.subplots(ncols=2, figsize=(10,4))\n",
    "\n",
    "# loss\n",
    "def plot_history_loss(fit):\n",
    "    # Plot the loss in the history\n",
    "    axL.plot(fit.history['loss'],label=\"loss for training\")\n",
    "    axL.plot(fit.history['val_loss'],label=\"loss for validation\")\n",
    "    axL.set_title('model loss')\n",
    "    axL.set_xlabel('epoch')\n",
    "    axL.set_ylabel('loss')\n",
    "    axL.legend(loc='upper right')\n",
    "\n",
    "# acc\n",
    "def plot_history_acc(fit):\n",
    "    # Plot the loss in the history\n",
    "    axR.plot(fit.history['acc'],label=\"accuracy for training\")\n",
    "    axR.plot(fit.history['val_acc'],label=\"accuracy for validation\")\n",
    "    axR.set_title('model accuracy')\n",
    "    axR.set_xlabel('epoch')\n",
    "    axR.set_ylabel('accuracy')\n",
    "    axR.legend(loc='upper right')\n",
    "\n",
    "plot_history_loss(fit)\n",
    "plot_history_acc(fit)\n",
    "fig.savefig(PLOT_FILE)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

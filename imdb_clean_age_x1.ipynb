{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean IMDB : age data\n",
    "\n",
    "**Source:** annotation_imdb_keras.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils_imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data = utils_imdb.IMDBDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imdb_data.IMDB_PATH)\n",
    "print(imdb_data.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas DataFrame\n",
    "imdb_data.to_pandas_dataframe(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"shape:\\t\", imdb_data.meta_df.shape)\n",
    "# print(imdb_data.meta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data.calculate_age()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data.is_image_valid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check if values of all rows are equal\n",
    "Compare: numpy.ndarray vs. pandas.DataFrame column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_path = imdb_data.meta[\"full_path\"][0]\n",
    "dob = imdb_data.meta[\"dob\"][0]\n",
    "gender = imdb_data.meta[\"gender\"][0]\n",
    "photo_taken = imdb_data.meta[\"photo_taken\"][0]\n",
    "face_score = imdb_data.meta[\"face_score\"][0]\n",
    "second_face_score = imdb_data.meta[\"second_face_score\"][0]\n",
    "name = imdb_data.meta[\"name\"][0]\n",
    "age = [utils_imdb.calc_age(photo_taken[i], dob[i]) for i in range(len(dob))]\n",
    "\n",
    "# find index of valid images\n",
    "valid = []\n",
    "for i in range(len(full_path)):\n",
    "    if(utils_imdb.is_valid(face_score[i],second_face_score[i],age[i],gender[i])):\n",
    "        valid.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import is_equal_to_df_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if values of all rows are equal\n",
    "check_column_names = ['age', 'dob', 'gender', 'photo_taken', 'face_score', 'second_face_score']\n",
    "for column_name in check_column_names:\n",
    "    is_equal, _, index_not_equal = is_equal_to_df_column(globals()[column_name], imdb_data.meta_df[column_name])\n",
    "    print(column_name, is_equal, sep='\\t', end='\\t' if len(index_not_equal) else '\\n')\n",
    "    if len(index_not_equal):\n",
    "        print(index_not_equal[:10], len(index_not_equal), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare valid and imdb_data.valid\n",
    "print('len:', len(valid), len(imdb_data.valid), sep='\\t')\n",
    "print('is equal?:', valid == imdb_data.valid, sep='\\t')\n",
    "print(valid[:20], imdb_data.valid[:20], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB : cleaning of age labels\n",
    "* nameID    nm...\n",
    "* imageID   rm...\n",
    "\n",
    "### Step 1: get unique imageID (rm id) from: full_path of path: imdb_crop\n",
    "= get dict which groups images by imageID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = utils_imdb.image_groups_by_rm_id(set(valid), imdb_data.meta_df.full_path.to_list())\n",
    "\n",
    "print('len(full_path)', len(full_path), sep=':\\t')\n",
    "print('len(valid)', len(valid), sep=':\\t')\n",
    "print('len(images)', len(images), sep=':\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: check duplicate images in each group\n",
    "\n",
    "For images in each group, check if they are duplicate.\n",
    "\n",
    "Source: https://stackoverflow.com/questions/51688179/check-if-there-is-exactly-the-same-image-as-input-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import utils\n",
    "import utils_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "importlib.reload(utils_csv)"
   ]
  },
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Warning *** Use with IMDB gender data set only\n",
    "# Remove duplicate images annotated with YoloKerasFaceDetection\n",
    "\n",
    "do_imdb_gender_remove_duplicate = True\n",
    "# do_imdb_gender_remove_duplicate = False\n",
    "\n",
    "do_move_files = False\n",
    "\n",
    "do_write_csv = True\n",
    "\n",
    "debug = False\n",
    "# debug = True\n",
    "verbose = True\n",
    "\n",
    "ext = \"jpg\"\n",
    "annotated_path = \"/home/krittametht/dataset/agegender_imdb/annotations/gender\"\n",
    "duplicate_path = annotated_path+\"_duplicate\"\n",
    "\n",
    "if do_imdb_gender_remove_duplicate:\n",
    "    utils_csv.prepare_csv_path()\n",
    "    csv_filepath = './csv/gender_duplicate.csv'\n",
    "    utils_csv.overwrite_and_clear_content(csv_filepath, [[duplicate_path]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if do_imdb_gender_remove_duplicate:\n",
    "    if verbose:\n",
    "        print('src path', annotated_path, sep=':\\t')\n",
    "        print('dst path', duplicate_path, sep=':\\t')\n",
    "\n",
    "    csv_file = open(csv_filepath, mode='a')\n",
    "    writer = utils_csv.create_csv_writer(csv_file)\n",
    "        \n",
    "    # -- for testing only\n",
    "    # images = {}\n",
    "    # images['rm2613630720'] = [(63200, 'https://www.imdb.com/name/nm0000507/mediaviewer/rm2613630720'), (138994, 'https://www.imdb.com/name/nm0004395/mediaviewer/rm2613630720'), (186283, 'https://www.imdb.com/name/nm2106637/mediaviewer/rm2613630720')]\n",
    "    # print(images)\n",
    "    \n",
    "    utils.prepare_dst_directory(duplicate_path)\n",
    "    filelist = utils.list_files(annotated_path, ext=ext)\n",
    "    \n",
    "    n_duplicates, operator = 2, 'gte' #ALL\n",
    "#     n_duplicates, operator = 5, 'gte'    \n",
    "#     n_duplicates, operator = 4, 'eql'\n",
    "#     n_duplicates, operator = 3, 'eql'\n",
    "#     n_duplicates, operator = 2, 'eql'\n",
    "    \n",
    "    ##image_group_iterator = images.items() # -- for testing only\n",
    "    print('# groups', len([key for key, _ in utils_imdb.iterate_filter_len(images, n_duplicates, operator)]), sep=':\\t')\n",
    "\n",
    "    print('\\n** BEGIN **: remove duplicate: IMDB Gender')\n",
    "    n = 0\n",
    "    for key, image_group in utils_imdb.iterate_filter_len(images, n_duplicates, operator):\n",
    "        files = utils.find_path_of_files(image_group, filelist, ext, annotated_path)\n",
    "        n += 1\n",
    "        if verbose and n % 100 == 0:    print(n)\n",
    "        \n",
    "        if len(files) <= 1:\n",
    "            if debug:    print('--continue')\n",
    "            continue\n",
    "\n",
    "        all_dup, is_duplicate = utils.all_images_duplicate(files)\n",
    "        if verbose:    print('>> ' + key + '\\t', len(image_group), len(files), all_dup, is_duplicate)\n",
    "        ##if debug:    print(all_dup, is_duplicate, sep='\\n')\n",
    "        if all_dup:\n",
    "            files_to_move = files[1:]\n",
    "            if do_write_csv:\n",
    "                for f in files_to_move:\n",
    "                    writer.writerow([f.replace(annotated_path + (\"\" if annotated_path[-1] == \"/\" else \"/\"), \"\")])\n",
    "            if do_move_files:\n",
    "                # keep the first, move out the rest\n",
    "                utils.move_files(files_to_move, annotated_path, duplicate_path, verbose=True)\n",
    "    print('** END **: remove duplicate: IMDB Gender:', n+1, 'groups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_csv.close_file(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main program flow: cleaning (age)\n",
    "Main Flow: remove duplicate \n",
    "* for not duplicate: check url changed (IMDB image ID valid ?)\n",
    "* get episode aired year\n",
    "* update photo taken (year)\n",
    "\n",
    "#### Flow: remove duplicate (age)\n",
    "* Google sheet > csv > read in python as pandas DataFrame \n",
    "* get image name which is \"in\" (not duplicate, has no wrong info)\n",
    "\n",
    "#### Mini task: \n",
    "(a) Try puppeteer block with multiple images (start with 20 images)\n",
    "\n",
    "(b) when cannot focus, go back to manual labelling (in Google sheet + jupyter notebook display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## > original / unique images without incorrect info\n",
    "not_duplicate = [112333, 112660, 184907, 29158, 199551, 278274, 278335, 269025, 390955, 55032, \n",
    "    340821, 91, 47, 428145, 50, 51, 433940, 100, 103, 109, 125, 1160] \n",
    "len(not_duplicate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puppeteer : extract episode air date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from pyppeteer import launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True\n",
    "# debug = False\n",
    "\n",
    "async def check_url_changed(page, url, go_to_url=True):\n",
    "    if go_to_url:\n",
    "        await page.goto(url)\n",
    "    return url != page.url\n",
    "\n",
    "\n",
    "async def get_aired_year(page, url):\n",
    "    xpath1 = '//div[@class=\"item-metadata\"]//strong[contains(text(),\"Titles\")]/following-sibling::a[2]'\n",
    "    els = await page.xpath(xpath1)\n",
    "    if debug:    print(els)\n",
    "    if len(els) != 1:\n",
    "        if debug:    print('e1: no episode link')\n",
    "        return None\n",
    "    href = await page.evaluate('(element) => element.href', els[0])\n",
    "    if debug:    print(href)\n",
    "            \n",
    "    await page.goto(href)\n",
    "    xpath2 = '//div[@class=\"subtext\"]//a[contains(text(),\"Episode aired\")]'\n",
    "    els_2 = await page.xpath(xpath2)\n",
    "    if debug:    print(els_2)\n",
    "    if len(els_2) != 1:\n",
    "        if debug:    print('e2: no episode aired date/year')\n",
    "        return None\n",
    "    text = await page.evaluate('(element) => element.textContent', els_2[0])\n",
    "\n",
    "    # extract string of aired year\n",
    "    str_year = text[-5:].strip() #last 4 characters\n",
    "    if debug:    print(text, str_year, sep='\\n')\n",
    "    aired_year = utils.str_to_int(str_year)\n",
    "\n",
    "    return aired_year\n",
    "\n",
    "\n",
    "async def main_pyppeteer():\n",
    "    df = imdb_data.meta_df\n",
    "    headless = False\n",
    "    headless = True\n",
    "\n",
    "#     > Real flow\n",
    "#     indices = not_duplicate[11:14] # NO episode link\n",
    "    indices = not_duplicate[:4] # have episode link\n",
    "    for index in indices:\n",
    "        name_id, rm_id, _, photo_taken = utils_imdb.serialize_filename(df.full_path.iloc[index])\n",
    "        url = utils_imdb.IMDB_url(name_id, rm_id)\n",
    "        if debug:    print('\\n> ' + str(index), df.name.iloc[index], sep=':\\t')\n",
    "        if debug:    print(url)\n",
    "        \n",
    "        aired_year = None\n",
    "        try:\n",
    "            browser = await launch(headless=headless) #****START****\n",
    "            try:\n",
    "                page = await browser.newPage() #****START****\n",
    "                await page.goto(url)\n",
    "                is_url_changed = await check_url_changed(page, url, go_to_url=False)\n",
    "                if debug:    print('is_url_changed ?', is_url_changed, sep='\\t')\n",
    "\n",
    "                if not is_url_changed:\n",
    "                    aired_year = await get_aired_year(page, url)\n",
    "                    if debug:    print(aired_year)\n",
    "            finally:\n",
    "                await page.close() #****END****\n",
    "                print('END1')\n",
    "\n",
    "            if aired_year is not None:\n",
    "                if debug:    print('aired_year == photo_taken (%d, %s)' % (aired_year, photo_taken), aired_year == int(photo_taken), sep=':\\t')\n",
    "        finally:\n",
    "            await browser.close() #****END****\n",
    "            print('END2')\n",
    "\n",
    "\n",
    "await asyncio.get_event_loop().run_until_complete(main_pyppeteer())"
   ]
  },
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
